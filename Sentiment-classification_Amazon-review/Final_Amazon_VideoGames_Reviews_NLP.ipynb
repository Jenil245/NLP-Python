{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "S9dzKGr3ZYb1",
    "outputId": "cbc9dce3-d109-4146-8949-a49993f5a05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dnspython\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d3/3aa0e7213ef72b8585747aa0e271a9523e713813b9a20177ebe1e939deb0/dnspython-1.16.0-py2.py3-none-any.whl (188kB)\n",
      "\r",
      "\u001b[K     |█▊                              | 10kB 24.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 20kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 30kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 40kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 51kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 61kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 71kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 81kB 4.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 92kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 102kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 112kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 122kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 133kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 143kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 153kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 163kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 174kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 184kB 4.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 194kB 4.7MB/s \n",
      "\u001b[?25hInstalling collected packages: dnspython\n",
      "Successfully installed dnspython-1.16.0\n",
      "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.6/dist-packages (3.10.1)\n",
      "Requirement already satisfied: dnspython<2.0.0,>=1.16.0; extra == \"srv\" in /usr/local/lib/python3.6/dist-packages (from pymongo[srv]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dnspython\n",
    "!pip install pymongo[srv]\n",
    "import nltk\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xgk9Q4R2TEhy"
   },
   "source": [
    "Here I have used amazon video games review data which I got from <a href=\"http://jmcauley.ucsd.edu/data/amazon/\">here</a> <br>\n",
    "Here data is in json format, I have imported this data into mongodb atlas cloud database just for learning purpose you can directly read json file in pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H04pNlkMZYb8"
   },
   "source": [
    "## Connect with Cloud mongodb atlas database and see available instance of database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y98gD6Q-ZYb-"
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\"mongodb+srv://user:user@cluster0-rgvhf.gcp.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "#for local mongodb you should do MongoClient(\"localhost\",27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RrmqGtftZYcC",
    "outputId": "8bf1784f-c8c8-446e-a32f-717e76b58be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reviews', 'admin', 'local']"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IdKKz3a-ZYcH",
    "outputId": "0682a63b-6d87-4933-f08d-be1fcc23bf0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['videogames']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=client['reviews']\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRFAwlnsZYcL"
   },
   "outputs": [],
   "source": [
    "collection=db['videogames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qlrZL3KbZYcP",
    "outputId": "9204685c-801d-45e7-f44f-f135b5611fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5e53e995a7c489e13c653798'), 'overall': 2.0, 'verified': True, 'reviewTime': '02 20, 2015', 'reviewerID': 'A2204E1TH211HT', 'asin': '0700026657', 'reviewerName': 'Grandma KR', 'reviewText': 'found the game a bit too complicated, not what I expected after having played 1602, 1503, and 1701', 'summary': 'Two Stars', 'unixReviewTime': 1424390400}\n"
     ]
    }
   ],
   "source": [
    "temp=collection.find_one()\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrUTpKFwZYcT"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMiglqu3ZYcU"
   },
   "source": [
    "There is no direct method for see which fields have NaN values<br>\n",
    "So We are gonna retrieve total number of entries and number of times key is present in data  <br>\n",
    "Data will be retrieved as list of dictionaries from collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kETNGk2VZYcV"
   },
   "outputs": [],
   "source": [
    "def do_count(collection):\n",
    "    temp=collection.find()\n",
    "    print(\"\\ncollection contains {0} entry\".format(temp.count())) #to see length of data\n",
    "\n",
    "    count_key={}\n",
    "    for item in temp:\n",
    "        for key in item:\n",
    "            if key in count_key:\n",
    "                count_key[key]+=1\n",
    "            else:\n",
    "                count_key[key]=1\n",
    "\n",
    "    print(count_key)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "xDpAcqDgZYcY",
    "outputId": "78c0321a-083b-4b2f-d48e-3403686b5450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "collection contains 497577 entry\n",
      "{'_id': 497577, 'overall': 497577, 'verified': 497577, 'reviewTime': 497577, 'reviewerID': 497577, 'asin': 497577, 'reviewerName': 497501, 'reviewText': 497419, 'summary': 497468, 'unixReviewTime': 497577, 'vote': 107793, 'style': 289237, 'image': 3634}\n"
     ]
    }
   ],
   "source": [
    "do_count(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klmdKoy2ZYcb"
   },
   "source": [
    "You can see that some fields does not contain value for each entry, we can say that they have NaN value in that entry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1muJfYrBZYcc"
   },
   "source": [
    "### Now let's retrive all data present in collection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "6cTDY1RxZYcd",
    "outputId": "53540d55-9efb-4794-fad1-02d3599f7b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.cursor.Cursor object at 0x7f351d373748>\n",
      "\n",
      " {'_id': ObjectId('5e53e99ca7c489e13c655ea8'), 'overall': 2.0, 'verified': False, 'reviewTime': '07 25, 2003', 'reviewerID': 'AGOHW680WF4KR', 'asin': 'B00002SU0O', 'reviewerName': 'Roy Levins', 'reviewText': 'THE GAME IS SLOW AND THERE IS NO WRESTLING MOVES.BUT YOU GET OUTSIDE THE RING ACTION WITH ANY WRESTLER.PS IF YOU WANT WRESTLING GET WWF RAW OR THE ROYAL RUMBLE FOR SNES.', 'summary': 'A SORRY GAME FOR WRESTLING.', 'unixReviewTime': 1059091200}\n"
     ]
    }
   ],
   "source": [
    "temp_data=collection.find()\n",
    "print(temp_data)\n",
    "\n",
    "print(\"\\n\",temp_data[10000])  #you can retrive single entry like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hto6sFRzZYcg"
   },
   "source": [
    "### Let's make dataframe of data which we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w29nAEIMZYch"
   },
   "outputs": [],
   "source": [
    "def retrive_usefuldata(all_data,reviews,ratings,summary):\n",
    "    review_list=[]\n",
    "    rating_list=[]\n",
    "    summary_list=[]\n",
    "    for item in all_data:\n",
    "        if reviews in item:                                       #remove elements which do not contain this field\n",
    "            if summary in item:                                    #remove elements which do not contain this field\n",
    "                review=item[reviews]\n",
    "                rating=item[ratings]\n",
    "                summary_t=item[summary]\n",
    "                \n",
    "                review_list.append(review)\n",
    "                rating_list.append(rating)\n",
    "                summary_list.append(summary_t)\n",
    "    \n",
    "    dictionary = {'user_reviews': review_list,'review_summary': summary_list ,'user_ratings': rating_list}\n",
    "        \n",
    "    useful_data=pd.DataFrame(dictionary)\n",
    "    return useful_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqVWhDIWZYcj"
   },
   "source": [
    "Above function will return reviews and corresponding summary and rating in dataframe object, you need to give just key names of this fields as per in dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "YwJUAcNQZYck",
    "outputId": "e3e41058-d25b-498f-9b4b-3646830893f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>user_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "      <td>But in spite of that it was fun, I liked it</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought this game thinking it would be pretty...</td>\n",
       "      <td>A very good game balance of skill with depth o...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ok game.</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I liked it and had fun with it, played for a w...</td>\n",
       "      <td>Pretty fun</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_reviews  ... user_ratings\n",
       "0  found the game a bit too complicated, not what...  ...          2.0\n",
       "1  I played it a while but it was alright. The st...  ...          4.0\n",
       "2  I bought this game thinking it would be pretty...  ...          5.0\n",
       "3                                           ok game.  ...          3.0\n",
       "4  I liked it and had fun with it, played for a w...  ...          4.0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=retrive_usefuldata(temp_data,'reviewText','overall','summary')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CP_Pb0hcZYcn"
   },
   "source": [
    "now we can perform nltk methods on above dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "KNYef0CAZYco",
    "outputId": "d5cf7ac5-8597-45e8-fec3-eb0d9aa36a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497316\n",
      "user_reviews      0\n",
      "review_summary    0\n",
      "user_ratings      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DmpRSlyqZYcr"
   },
   "source": [
    "As you know before we had 497577 raw and now we have 497316 raw , that's because we had some NaN values which we removed inside funtion <br> so now we have cleaned data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vvY0fqv7ZYcs",
    "outputId": "2b777e32-3bbb-42ae-def1-4479e1d80ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5.0: 299541, 4.0: 93636, 3.0: 49138, 1.0: 30872, 2.0: 24129}\n"
     ]
    }
   ],
   "source": [
    "print(dict(data['user_ratings'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLiBmXOXZYcv"
   },
   "source": [
    "As you can see we have very imbalanced data but it's not a surprise since we know that people only buy product in which they are intersted so they are highly likely to give more ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yx6xVrpWZYcw"
   },
   "source": [
    "### Creating Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AkODpW7ZYcx"
   },
   "source": [
    "There are mainly three methods for handling imbalanced dataset <br>\n",
    "<ol><li>Under Sampling</li>\n",
    "    <li>Over Sampling</li>\n",
    "    <li>SMOTE(Synthetic Minority Oversampling Technique)</li></ol><br>\n",
    "In Under Sampling we simply remove observations from the majority class As In Over Sampling we simply increase observations from the minority class by repeating them until both observations are same<br>\n",
    "\n",
    "SMOTE is a very powerful technique which generates new minority samples. You can learn more about this <a href=\"https://arxiv.org/pdf/1106.1813.pdf\">here</a><br>\n",
    "And You can perform SMOTE in python by referring <a href=\"https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\">this</a> <br>\n",
    "\n",
    "<b>Since We have too much data and it will take too much time for training a model on this data so here we will take ten thousand sample for each class</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pQ2TKAD_ZYc0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def creating_balanced_dataset(dataset,column,count):\n",
    "    temp_dict=dict(dataset[column].value_counts())\n",
    "    indices=[]\n",
    "    for item in temp_dict:\n",
    "        temp_indices=dataset[dataset[column]==item].sample(count).index\n",
    "        indices=temp_indices.union(indices)\n",
    "    balanced_dataset=dataset.loc[indices]\n",
    "    balanced_dataset.reset_index(drop=True,inplace=True)\n",
    "    return balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "l0KbGTKgZYc2",
    "outputId": "27b7e86f-4037-4b00-e915-e4480c9a2d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0    10000\n",
      "5.0    10000\n",
      "1.0    10000\n",
      "4.0    10000\n",
      "2.0    10000\n",
      "Name: user_ratings, dtype: int64\n",
      "(50000, 3)\n"
     ]
    }
   ],
   "source": [
    "balanced_data=creating_balanced_dataset(data,'user_ratings',10000)\n",
    "\n",
    "print(balanced_data['user_ratings'].value_counts())\n",
    "print(balanced_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzSHSr07ZYc5"
   },
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "HbfYnvnoZYc6",
    "outputId": "9d1b4a73-e4ae-45b6-be0f-65c68c1b7487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBVBElTw4Tqm"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "0z5BW1GgZYc-",
    "outputId": "9ebaae40-19a7-4160-8ea2-ca685def5153"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reviews</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>user_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I liked it and had fun with it, played for a w...</td>\n",
       "      <td>Pretty fun</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've bought and played ALL of the ANNO games s...</td>\n",
       "      <td>SAY NO TO DRM!!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>DIRT 3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I still haven't figured this one out. Did ever...</td>\n",
       "      <td>Couldn't get this one to work</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_reviews  ... user_ratings\n",
       "0  found the game a bit too complicated, not what...  ...          2.0\n",
       "1  I liked it and had fun with it, played for a w...  ...          4.0\n",
       "2  I've bought and played ALL of the ANNO games s...  ...          1.0\n",
       "3  I had Dirt 2 on Xbox 360 and it was an okay ga...  ...          4.0\n",
       "4  I still haven't figured this one out. Did ever...  ...          2.0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCeHfODLZYdC"
   },
   "source": [
    "Let's combine both review columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "N03vulLsZYdD",
    "outputId": "189dff52-57be-4a5e-c1ba-ee9f66e5e615"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ratings</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked it and had fun with it, played for a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I've bought and played ALL of the ANNO games s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I still haven't figured this one out. Did ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ratings                                             review\n",
       "0           2.0  found the game a bit too complicated, not what...\n",
       "1           4.0  I liked it and had fun with it, played for a w...\n",
       "2           1.0  I've bought and played ALL of the ANNO games s...\n",
       "3           4.0  I had Dirt 2 on Xbox 360 and it was an okay ga...\n",
       "4           2.0  I still haven't figured this one out. Did ever..."
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data['review']=balanced_data['user_reviews']+balanced_data['review_summary']\n",
    "\n",
    "balanced_data.drop(columns=['user_reviews','review_summary'],inplace=True)\n",
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kUsUoEI8ZYdF"
   },
   "source": [
    "Now let's remove all things except characters <br>\n",
    "Also remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPm4KEI_ZYdG"
   },
   "outputs": [],
   "source": [
    "def clean_review(data,column):\n",
    "    data[column] = data[column].apply(lambda x:re.sub('[^a-zA-Z ]+','',str(x)))\n",
    "    \n",
    "    data[column] = data[column].apply(nltk.word_tokenize)\n",
    "    \n",
    "    data[column] = data[column].apply(lambda x:[word.lower() for word in x])   #transform words in lowercase\n",
    "\n",
    "    data[column] = data[column].apply(lambda x: [word for word in x if word not in stop_words]) #removing stop words \n",
    "\n",
    "    data[column] = data[column].apply(lambda x:' '.join(x))    #join all words as sentenance\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "-ikEUChlZYdI",
    "outputId": "20790493-5e1c-415c-c236-09e45853b312"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ratings</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>found game bit complicated expected played two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>liked fun played got moneys worth certainly go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ive bought played anno games since spent hours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dirt xbox okay game started playing games lapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>still havent figured one everything instructed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ratings                                             review\n",
       "0           2.0  found game bit complicated expected played two...\n",
       "1           4.0  liked fun played got moneys worth certainly go...\n",
       "2           1.0  ive bought played anno games since spent hours...\n",
       "3           4.0  dirt xbox okay game started playing games lapt...\n",
       "4           2.0  still havent figured one everything instructed..."
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data=clean_review(balanced_data,'review')\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUfKkTfFZYdL"
   },
   "source": [
    "Classfying five class is very hard, we can not get high accuracy as we can get for binary classification<br>\n",
    "So we will make comparison between both situation<br>\n",
    "For binary classification We will group [1,2] as low and [3,4,5] as high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "id": "So8yd0DeZYdP",
    "outputId": "0319c67f-ede4-4e6f-9199-a79c3c5a6366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high    30000\n",
      "low     20000\n",
      "Name: binary_rating, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ratings</th>\n",
       "      <th>review</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>found game bit complicated expected played two...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>liked fun played got moneys worth certainly go...</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ive bought played anno games since spent hours...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>dirt xbox okay game started playing games lapt...</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>still havent figured one everything instructed...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ratings  ... binary_rating\n",
       "0           2.0  ...           low\n",
       "1           4.0  ...          high\n",
       "2           1.0  ...           low\n",
       "3           4.0  ...          high\n",
       "4           2.0  ...           low\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_rating=[]\n",
    "for item in cleaned_data['user_ratings']:\n",
    "    if item>=3:\n",
    "        binary_rating.append('high')\n",
    "    else:\n",
    "        binary_rating.append('low')\n",
    "cleaned_data=pd.concat([cleaned_data,pd.Series(binary_rating,name='binary_rating')],axis=1) \n",
    "print(cleaned_data['binary_rating'].value_counts(),'\\n')\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gGAkbtrZYdW"
   },
   "source": [
    "<b>creating balanced dataset for binary classification</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "cU4iRdJiZYdY",
    "outputId": "6e6b4bdd-aab7-43bb-98e0-df061733825b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3)\n",
      "high    20000\n",
      "low     20000\n",
      "Name: binary_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "binary_balanced_data=creating_balanced_dataset(cleaned_data,'binary_rating',20000)\n",
    "\n",
    "print(binary_balanced_data.shape)\n",
    "print(binary_balanced_data['binary_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2MN-tgOZYdf"
   },
   "source": [
    "Now We will perform Tfidf vectorization on text content to convert in numbers since computer works best with number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "jTchZOBGZYdh",
    "outputId": "4a9f8486-d5fb-4ea9-cb5c-d3c1efed7a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 20000)\n",
      "(50000, 20000)\n"
     ]
    }
   ],
   "source": [
    "binary_tfidf = TfidfVectorizer(max_features=20000)\n",
    "binary_word_matrix=binary_tfidf.fit_transform(binary_balanced_data['review'])\n",
    "print(binary_word_matrix.shape)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=20000)\n",
    "word_matrix=tfidf.fit_transform(cleaned_data['review'])\n",
    "print(word_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoeErR3yZYdo"
   },
   "outputs": [],
   "source": [
    "binary_target=binary_balanced_data['binary_rating']\n",
    "target=cleaned_data['user_ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQNwD6ulMHKj"
   },
   "source": [
    "For training a model in keras we should encode and transform our target variable as follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "geXp_YICHMO6",
    "outputId": "e75b9abf-da1b-41b3-a085-ef2df33a05d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encoded=encoder.fit_transform(binary_target)\n",
    "for_keras = to_categorical(encoded,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "W3LJu5M0PTF3",
    "outputId": "1e1f3171-9360-4160-b817-b57261a5225a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSBHpOfEZYdu"
   },
   "source": [
    "# MODEL DEVELOPEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJtqksxnZYdw"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNVTwPQRNC_o"
   },
   "source": [
    "We will create three different training and testing set where first one is for binary classification, second one is for multiclass classification and third one is for keras binary classification<br>\n",
    "I will not train keras model for multiclass classification since it doesn't improve accuracy in classifying as I observe in binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NsJnnQJRZYdz"
   },
   "outputs": [],
   "source": [
    "btrain_x,btest_x,btrain_y,btest_y=train_test_split(binary_word_matrix,binary_target,test_size=0.05, random_state=42) \n",
    "train_x,test_x,train_y,test_y=train_test_split(word_matrix,target,test_size=0.05, random_state=42)\n",
    "\n",
    "kbtrain_x,kbtest_x,kbtrain_y,kbtest_y=train_test_split(binary_word_matrix,for_keras,test_size=0.05, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04bi5A80ZYd3"
   },
   "source": [
    "#### Binary Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Nija4BmUZYd6",
    "outputId": "ff0ad7f9-49a2-4b45-f0e4-cefda305aebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83 \n",
      "\n",
      "[[825 172]\n",
      " [168 835]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.83      0.83       997\n",
      "         low       0.83      0.83      0.83      1003\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      " \n",
      "\n",
      "0.8158947368421053\n"
     ]
    }
   ],
   "source": [
    "binary_lr=LogisticRegression()\n",
    "\n",
    "binary_lr.fit(btrain_x,btrain_y)\n",
    "\n",
    "blr_pred=binary_lr.predict(btest_x)\n",
    "\n",
    "print(accuracy_score(btest_y,blr_pred),'\\n')\n",
    "print(confusion_matrix(btest_y,blr_pred),'\\n')\n",
    "print(classification_report(btest_y,blr_pred),'\\n')\n",
    "\n",
    "print(cross_val_score(binary_lr,btrain_x,btrain_y,cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "IQyFis2KZYd9",
    "outputId": "e40b2a9d-86b2-4948-bfef-497497d9808c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085 \n",
      "\n",
      "[[782 215]\n",
      " [168 835]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.82      0.78      0.80       997\n",
      "         low       0.80      0.83      0.81      1003\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.81      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_rf=RandomForestClassifier()\n",
    "\n",
    "binary_rf.fit(btrain_x,btrain_y)\n",
    "\n",
    "brf_pred=binary_rf.predict(btest_x)\n",
    "\n",
    "print(accuracy_score(btest_y,brf_pred),'\\n')\n",
    "print(confusion_matrix(btest_y,brf_pred),'\\n')\n",
    "print(classification_report(btest_y,brf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "lelNnIzgZYeA",
    "outputId": "ba9b2add-3938-415d-cda6-1ac4d35f799a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7475 \n",
      "\n",
      "[[722 275]\n",
      " [230 773]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.76      0.72      0.74       997\n",
      "         low       0.74      0.77      0.75      1003\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.75      0.75      0.75      2000\n",
      "weighted avg       0.75      0.75      0.75      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_xgb=XGBClassifier()\n",
    "\n",
    "binary_xgb.fit(btrain_x,btrain_y)\n",
    "\n",
    "bxgb_pred=binary_xgb.predict(btest_x)\n",
    "\n",
    "print(accuracy_score(btest_y,bxgb_pred),'\\n')\n",
    "print(confusion_matrix(btest_y,bxgb_pred),'\\n')\n",
    "print(classification_report(btest_y,bxgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gmnl2H2zZYeW"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "lgI3oSFWZYeY",
    "outputId": "fc9b34e6-3152-4b51-c7ca-aebf153b6a58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_model = Sequential()\n",
    "binary_model.add(Dense(10000, activation='relu', input_dim=20000))\n",
    "binary_model.add(Dropout(0.1))\n",
    "binary_model.add(Dense(1000, activation='relu'))\n",
    "binary_model.add(Dropout(0.1))\n",
    "binary_model.add(Dense(100, activation='relu'))\n",
    "binary_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "binary_model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "oV50-jKxZYec",
    "outputId": "f0dd18c4-f5b6-4c4d-eddb-115acc02cfad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "38000/38000 [==============================] - 34s 900us/step - loss: 0.4396 - acc: 0.7919\n",
      "Epoch 2/3\n",
      "38000/38000 [==============================] - 23s 612us/step - loss: 0.3035 - acc: 0.8716\n",
      "Epoch 3/3\n",
      "38000/38000 [==============================] - 23s 611us/step - loss: 0.1746 - acc: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34ee6e4828>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model.fit(kbtrain_x,kbtrain_y,epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "rg4iWFvKFZ5x",
    "outputId": "53158653-e976-4ef3-b321-f86a65add906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000/38000 [==============================] - 6s 170us/step\n",
      "2000/2000 [==============================] - 0s 171us/step\n",
      "training accuracy:0.9745263157894737 \n",
      "\n",
      "testing accuracy:0.808 \n",
      "\n",
      "[[0.02259083 0.9774091 ]\n",
      " [0.00215436 0.99784565]\n",
      " [0.13627647 0.8637235 ]\n",
      " ...\n",
      " [0.7304234  0.26957664]\n",
      " [0.9893373  0.01066263]\n",
      " [0.8059728  0.19402719]]\n"
     ]
    }
   ],
   "source": [
    "keras_pred=binary_model.predict(kbtest_x)\n",
    "\n",
    "train_score = binary_model.evaluate(kbtrain_x,kbtrain_y)\n",
    "\n",
    "test_score = binary_model.evaluate(kbtest_x,kbtest_y)\n",
    "\n",
    "print(\"training accuracy:{0}\".format(train_score[1]),'\\n')\n",
    "print(\"testing accuracy:{0}\".format(test_score[1]),'\\n')\n",
    "\n",
    "print(keras_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wwpn8QwJOWIH"
   },
   "source": [
    "As you can see logistic regression works best and it's also very simple algorithm as it simply draws line between two class<br>\n",
    "rf and keras also performed well<br>\n",
    "I would not recommend using SVM because it's very high computational and time consuming algorithm and accuracy is not increasing that much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZZcjEAbZYeC"
   },
   "source": [
    "#### Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "Ngre0Ks6ZYeD",
    "outputId": "275081f8-8775-4830-a737-6b37e2d8c2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572 \n",
      "\n",
      "[[356 113  29   9   9]\n",
      " [121 213  98  41  19]\n",
      " [ 42 104 224 106  39]\n",
      " [ 21  33  93 245  95]\n",
      " [ 19  11  25  80 355]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.69      0.66       516\n",
      "         2.0       0.45      0.43      0.44       492\n",
      "         3.0       0.48      0.43      0.46       515\n",
      "         4.0       0.51      0.50      0.51       487\n",
      "         5.0       0.69      0.72      0.71       490\n",
      "\n",
      "    accuracy                           0.56      2500\n",
      "   macro avg       0.55      0.56      0.55      2500\n",
      "weighted avg       0.55      0.56      0.55      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "\n",
    "lr.fit(train_x,train_y)\n",
    "\n",
    "lr_pred=lr.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,lr_pred),'\\n')\n",
    "print(confusion_matrix(test_y,lr_pred),'\\n')\n",
    "print(classification_report(test_y,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "CL6fVJaLZYeJ",
    "outputId": "a4f158c8-a936-481f-ec6c-68bdf7392da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5056 \n",
      "\n",
      "[[375  85  31  14  11]\n",
      " [139 188  89  44  32]\n",
      " [ 82 111 179  98  45]\n",
      " [ 49  43  82 218  95]\n",
      " [ 30  35  28  93 304]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.73      0.63       516\n",
      "         2.0       0.41      0.38      0.39       492\n",
      "         3.0       0.44      0.35      0.39       515\n",
      "         4.0       0.47      0.45      0.46       487\n",
      "         5.0       0.62      0.62      0.62       490\n",
      "\n",
      "    accuracy                           0.51      2500\n",
      "   macro avg       0.50      0.50      0.50      2500\n",
      "weighted avg       0.50      0.51      0.50      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(train_x,train_y)\n",
    "\n",
    "rf_pred=rf.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,rf_pred),'\\n')\n",
    "print(confusion_matrix(test_y,rf_pred),'\\n')\n",
    "print(classification_report(test_y,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "F1b9pbl2ZYeM",
    "outputId": "a2f0f603-207a-4007-bb15-befab7124ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4568 \n",
      "\n",
      "[[363  83  14  33  23]\n",
      " [156 148  62  71  55]\n",
      " [114  81 138 112  70]\n",
      " [ 74  47  51 196 119]\n",
      " [ 65  21  15  92 297]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.47      0.70      0.56       516\n",
      "         2.0       0.39      0.30      0.34       492\n",
      "         3.0       0.49      0.27      0.35       515\n",
      "         4.0       0.39      0.40      0.40       487\n",
      "         5.0       0.53      0.61      0.56       490\n",
      "\n",
      "    accuracy                           0.46      2500\n",
      "   macro avg       0.45      0.46      0.44      2500\n",
      "weighted avg       0.45      0.46      0.44      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb=XGBClassifier()\n",
    "\n",
    "xgb.fit(train_x,train_y)\n",
    "\n",
    "xgb_pred=xgb.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,xgb_pred),'\\n')\n",
    "print(confusion_matrix(test_y,xgb_pred),'\\n')\n",
    "print(classification_report(test_y,xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EASOhJSqPLNn"
   },
   "source": [
    "Here also logistic regression outperformed other algorithms and it's also easy to train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4to9Am7PnPb"
   },
   "source": [
    "To increase accuracy you can perform hyperparameter optimization, you can also combine two or three algorithms and create hybrid model which will also perform better <br>\n",
    "However I would not recommend increasing training sample or feature set because I have already done that and it will not improve accuracy."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Amazon VideoGames_Reviews NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
