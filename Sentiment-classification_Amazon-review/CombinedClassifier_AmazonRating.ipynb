{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINED MODEL DEVELOPEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I am going to create combined model which is consists of seven classifiers \n",
    "\n",
    "I have processed and cleaned amazon review data in other notebook which is also uploded as Final<br>\n",
    "Here I have just compared different model for binary classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from statistics import mode\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"binaryrating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>binary_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>found game bit complicated expected played two...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im sure would love game could play loved hitma...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like bf game work wireless xbox controller don...</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>game requires open online account play game co...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st shipment received book instead gamend shipm...</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review binary_rating\n",
       "0  found game bit complicated expected played two...           low\n",
       "1  im sure would love game could play loved hitma...           low\n",
       "2  like bf game work wireless xbox controller don...          high\n",
       "3  game requires open online account play game co...           low\n",
       "4  st shipment received book instead gamend shipm...           low"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 20000)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000)\n",
    "word_matrix=tfidf.fit_transform(data['review'].values.astype('U'))\n",
    "print(word_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(word_matrix,data['binary_rating'],test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305 \n",
      "\n",
      "[[823 185]\n",
      " [154 838]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.84      0.82      0.83      1008\n",
      "         low       0.82      0.84      0.83       992\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred=lr.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,test_pred),'\\n')\n",
    "print(confusion_matrix(test_y,test_pred),'\\n')\n",
    "print(classification_report(test_y,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716 \n",
      "\n",
      "[[831 177]\n",
      " [391 601]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.68      0.82      0.75      1008\n",
      "         low       0.77      0.61      0.68       992\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.73      0.72      0.71      2000\n",
      "weighted avg       0.73      0.72      0.71      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pred=knn.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,knn_pred),'\\n')\n",
    "print(confusion_matrix(test_y,knn_pred),'\\n')\n",
    "print(classification_report(test_y,knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=SGDClassifier()\n",
    "sgd.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831 \n",
      "\n",
      "[[827 181]\n",
      " [157 835]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.84      0.82      0.83      1008\n",
      "         low       0.82      0.84      0.83       992\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_pred=sgd.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,sgd_pred),'\\n')\n",
    "print(confusion_matrix(test_y,sgd_pred),'\\n')\n",
    "print(classification_report(test_y,sgd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB=MultinomialNB()\n",
    "NB.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085 \n",
      "\n",
      "[[792 216]\n",
      " [167 825]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.79      0.81      1008\n",
      "         low       0.79      0.83      0.81       992\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.81      0.81      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_pred=NB.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,NB_pred),'\\n')\n",
    "print(confusion_matrix(test_y,NB_pred),'\\n')\n",
    "print(classification_report(test_y,NB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=LinearSVC()\n",
    "svc.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 \n",
      "\n",
      "[[823 185]\n",
      " [175 817]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.82      0.82      0.82      1008\n",
      "         low       0.82      0.82      0.82       992\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_pred=svc.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,svc_pred),'\\n')\n",
    "print(confusion_matrix(test_y,svc_pred),'\\n')\n",
    "print(classification_report(test_y,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier()\n",
    "xgb.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764 \n",
      "\n",
      "[[718 290]\n",
      " [182 810]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.80      0.71      0.75      1008\n",
      "         low       0.74      0.82      0.77       992\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.77      0.76      0.76      2000\n",
      "weighted avg       0.77      0.76      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred=xgb.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,xgb_pred),'\\n')\n",
    "print(confusion_matrix(test_y,xgb_pred),'\\n')\n",
    "print(classification_report(test_y,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824 \n",
      "\n",
      "[[793 215]\n",
      " [137 855]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.85      0.79      0.82      1008\n",
      "         low       0.80      0.86      0.83       992\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.83      0.82      0.82      2000\n",
      "weighted avg       0.83      0.82      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pred=rf.predict(test_x)\n",
    "\n",
    "print(accuracy_score(test_y,rf_pred),'\\n')\n",
    "print(confusion_matrix(test_y,rf_pred),'\\n')\n",
    "print(classification_report(test_y,rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let's save our models as elements of list in pickle file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#model=[lr,knn,sgd,NB,svc,xgb,rf]\n",
    "#f = open(\"binaryreview_classification.pkl\", \"wb\")\n",
    "#pickle.dump(model,f)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "f = open(\"binaryreview_classification.pkl\",\"rb\")\n",
    "a=pickle.load(f)\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data):\n",
    "    predicted=[]\n",
    "    confidence=[]\n",
    "    \n",
    "    for model in a:\n",
    "        pred=model.predict(data)\n",
    "        pred_list=pred.tolist()\n",
    "            \n",
    "        if(len(predicted)==0):\n",
    "            predicted=predicted+pred_list\n",
    "        else:\n",
    "            for i in range(0,len(pred_list)):\n",
    "                predicted[i]=predicted[i] +\"|\"+ pred_list[i]\n",
    "                \n",
    "    for i in range(0,len(predicted)):\n",
    "        predicted[i]=predicted[i].split('|')\n",
    "        confidence.append((predicted[i].count(mode(predicted[i]))/len(predicted[i]))*100)\n",
    "        predicted[i]=mode(predicted[i])\n",
    "            \n",
    "    return predicted,confidence       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above function will return prediction with confidence<br>\n",
    "I have used voting system means whichever label has more vote will be shown as output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_pred,confidence=classify(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:low with confidence:85.71428571428571 and actual:low\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction:{0} with confidence:{1} and actual:{2}\".format(combine_pred[656],confidence[656],test_y.iloc[656]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.836 \n",
      "\n",
      "[[830 178]\n",
      " [150 842]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.85      0.82      0.84      1008\n",
      "         low       0.83      0.85      0.84       992\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_y,combine_pred),'\\n')\n",
    "print(confusion_matrix(test_y,combine_pred),'\\n')\n",
    "print(classification_report(test_y,combine_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see accuracy is nearly same as individual models but plus point is that now we can see confidence Hence we can be more sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key Points: </b>\n",
    "\n",
    "SGD , RF and XGB relatively takes more time in training then other algorithms\n",
    "           \n",
    "SVC kernel algorithm takes highest amount time since it has to do lot of computation, Here we have used SVC linear which is very fast to train\n",
    "\n",
    "SVC linear and LR are basically same, only difference is there loss function\n",
    "\n",
    "You can save multiple models in pickle file as lists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
