{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "review_predict_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzWP7EbhK7-L",
        "colab_type": "text"
      },
      "source": [
        "# LSTM sentiment classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ialosoK7-T",
        "colab_type": "text"
      },
      "source": [
        "#### I have implemented BoW and TfIdf models But those model just predict based on frequency of word , they do not preserve semantic meaning , As in this model it will predict sentiment based on whole review.\n",
        "\n",
        "Here I will take fraction of data since training this model is very costly in terms of GPU and also I have taken only one LSTM layer so model structure is simple but you can change this to get higher accuracy score if you have resources \n",
        "\n",
        "I have processed and cleaned amazon review data in other notebook which is also uploded as Final on github<br>\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zk3jEUnK7-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n",
        "from statistics import mode\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wLJ1S8hK7-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"binaryrating.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnUkfbdK7-4",
        "colab_type": "code",
        "outputId": "0bb8a33d-908a-44fe-bc98-7b1ba9d0b798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>binary_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>found game bit complicated expected played two...</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im sure would love game could play loved hitma...</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like bf game work wireless xbox controller don...</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>game requires open online account play game co...</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>st shipment received book instead gamend shipm...</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review binary_rating\n",
              "0  found game bit complicated expected played two...           low\n",
              "1  im sure would love game could play loved hitma...           low\n",
              "2  like bf game work wireless xbox controller don...          high\n",
              "3  game requires open online account play game co...           low\n",
              "4  st shipment received book instead gamend shipm...           low"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MswcPVXWK7_D",
        "colab_type": "code",
        "outputId": "b5ed84fc-598b-4126-e4e6-d42620d11358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eSqjOLuK7_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "data['review'] = data['review'].apply(lambda x:re.sub('[^a-zA-Z ]+','',str(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_GGvHF3K7_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(data):\n",
        "    tz = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n[0-9]', lower=True, split=' ')\n",
        "    tz.fit_on_texts(data)\n",
        "    total_words = len(tz.word_index)\n",
        "    \n",
        "    input_sequences = []\n",
        "    for line in data:\n",
        "        token_list = tz.texts_to_sequences([line])[0]\n",
        "        input_sequences.append(token_list)    \n",
        "    max_len_sequence = max([len(x) for x in input_sequences])\n",
        "    padded_sequence = np.array(pad_sequences(input_sequences, maxlen = max_len_sequence, padding = 'pre'))  #using pad_sequence for generating same dimensions training data\n",
        "    \n",
        "    return padded_sequence,max_len_sequence,total_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymsuzXgKMWzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors,max_len_sequence,total_words=prepare_data(data['review'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0jWOSDRK7_l",
        "colab_type": "code",
        "outputId": "f0757197-c3e4-42c5-dde1-602234f5fc81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(predictors.shape,'\\n')\n",
        "print(max_len_sequence,'\\n')\n",
        "print(total_words)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 2967) \n",
            "\n",
            "2967 \n",
            "\n",
            "116287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQE2a2KK7_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(max_len_sequence, total_words):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(total_words+1, 10, input_length=max_len_sequence))\n",
        "    \n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P5b_Qj3K7_y",
        "colab_type": "code",
        "outputId": "860a2a8e-1c3e-4842-cc82-b000f88ada4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model = create_model(max_len_sequence, total_words)\n",
        "\n",
        "print(model.summary(),'\\n')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 2967, 10)          1162880   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,207,381\n",
            "Trainable params: 1,207,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjLR-QhyK7_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f978d767-6e45-4fcb-f1de-1fccd8efffaa"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()\n",
        "target=encoder.fit_transform(data['binary_rating'])\n",
        "\n",
        "train_x,test_x,train_y,test_y=train_test_split(predictors,target,test_size=0.6, random_state=42)\n",
        "\n",
        "print(target[:5])\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 1 1]\n",
            "(16000, 2967)\n",
            "(24000, 2967)\n",
            "(16000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqt330RYK7_2",
        "colab_type": "code",
        "outputId": "610c6bc5-c9f5-47ca-8816-41a1ff0c8d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "model.fit(train_x,train_y,epochs=5,batch_size=128)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16000/16000 [==============================] - 545s 34ms/step - loss: 0.6072 - acc: 0.6551\n",
            "Epoch 2/5\n",
            "16000/16000 [==============================] - 542s 34ms/step - loss: 0.3640 - acc: 0.8465\n",
            "Epoch 3/5\n",
            "16000/16000 [==============================] - 584s 37ms/step - loss: 0.3119 - acc: 0.8742\n",
            "Epoch 4/5\n",
            "16000/16000 [==============================] - 561s 35ms/step - loss: 0.2153 - acc: 0.9182\n",
            "Epoch 5/5\n",
            "16000/16000 [==============================] - 562s 35ms/step - loss: 0.1519 - acc: 0.9471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3cf05b4278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NXKBskvT6cA",
        "colab_type": "code",
        "outputId": "d13297bb-8325-4bfa-dffe-1584d871c970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "pred=model.predict_classes(test_x)\n",
        "print(confusion_matrix(test_y,pred))\n",
        "print(accuracy_score(test_y,pred))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9962 1959]\n",
            " [2841 9238]]\n",
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZib7o9JVYY0",
        "colab_type": "text"
      },
      "source": [
        "We got same accuracy as before with Tfidf model\n",
        "\n",
        "Some ways we can improve accuracy is:\n",
        "<ul>\n",
        "<li>\n",
        "Take more data and use more layer in model</li>\n",
        "<li>\n",
        "use pretained embedding vectors e.g. Word2Vec instead of training them from scratch because Word2Vec is trianed on billions of words so it will have more accurate representation of words.</li>\n",
        "<li>use bi-directional lstm </li>\n",
        "</ul>"
      ]
    }
  ]
}